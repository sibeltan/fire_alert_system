{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have collected tweets from most recent California wildfires based on below locations and time frames: \n",
    "\n",
    "**Pre-fire tweets**     \n",
    "San Fernando Valley / 08/20/2019 - 09/06/2019  \n",
    "**Post-fire tweets**  \n",
    "1- La Tuna Canyon / 09/01/2017 - 09/01/2017  \n",
    "2- Kincade / 10/24/2019 - 10/28/2019  \n",
    "3- Santa Clarita (Tick Fire) / 10/26/2019 - 10/28/2019     \n",
    "4- Saddleridge / 10/19/2019 - 10/24/2019  \n",
    "5- Getty Center / 10/28/2019 - 10/29/2019  \n",
    "6- Santa Paula (Maria Fire) - 10/31/2019 - 11/01/2019  \n",
    "\n",
    "Then, we have labeled all pre-fire tweets as negative class (Target = 0) and manually labeled all post-fire tweets one by one. If a tweets is both relevant and informative, then the target value is (Target = 1), otherwise (Target = 0)\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Using Tweepy Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Tweepy library to create a daily scraper for newest tweets based on location and date filters since Twitter API allows to scrape the tweets posted within last 7 days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing the API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It requires to create a Twitter developer account and create an app to obtain consumer keys and access tokens.  \n",
    "For further information: https://developer.twitter.com/en.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "import tweepy\n",
    "import csv\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store your twitter credentials\n",
    "\n",
    "twitter_cred = dict()\n",
    "\n",
    "twitter_cred['CONSUMER_KEY'] = '***********************'\n",
    "twitter_cred['CONSUMER_SECRET'] = '***********************'\n",
    "twitter_cred['ACCESS_KEY'] = '***********************'\n",
    "twitter_cred['ACCESS_SECRET'] = '***********************'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the information to a json so that it can be reused in code\n",
    "\n",
    "with open('twitter_cred.json', 'w') as secret_info:\n",
    "    json.dump(twitter_cred, secret_info, sort_keys=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find twitter_cred.json file in current directory and type consumer key, consumer secret, access key, access secret. After this, do not re-run above cell since it would overwrite the file with blank data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Twitter API credentials\n",
    "\n",
    "with open('twitter_cred.json') as cred_data:\n",
    "    info = json.load(cred_data)\n",
    "    consumer_key = info['CONSUMER_KEY']\n",
    "    consumer_secret = info['CONSUMER_SECRET']\n",
    "    access_token = info['ACCESS_KEY']\n",
    "    access_secret = info['ACCESS_SECRET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authorization and initialization\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://tweepy.readthedocs.io/en/latest/code_snippet.html\n",
    "    \n",
    "# specify a keyword i.e fire\n",
    "# if you assign blank string, it will pull all tweets\n",
    "keyword = ''\n",
    "\n",
    "# get today's date\n",
    "today = str(date.today())\n",
    "\n",
    "# open/create a file to save data\n",
    "csv_file = open('/data/maria_fire_20191101.csv', 'a')\n",
    "\n",
    "# define csv writer\n",
    "csv_writer = csv.writer(csv_file)\n",
    "    \n",
    "for tweet in tweepy.Cursor(api.search,\n",
    "                           q=' maria fire',\n",
    "                           count=100,\n",
    "                           geocode='34.3542, -119.0593, 30mi', # longitude, latitude, radius (need to update for different locations)\n",
    "                           lang=\"en\",\n",
    "                           since=today).items(): # .items() is for paging tweets \n",
    "    \n",
    "    # print(tweet.created_at, tweet.text)\n",
    "    # condition to exclude retweets\n",
    "    # if not (tweet.retweeted) and ('RT @' not in tweet.text) and ('https://' not in tweet.text): \n",
    "    \n",
    "    # append the dataset file\n",
    "    csv_writer.writerow([tweet.created_at, tweet.text.encode('utf-8'), tweet.retweet_count, tweet.favorite_count]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe from csv file \n",
    "tweet_df = pd.read_csv('../data/maria_fire_20191101.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2297, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign appropriate column names\n",
    "tweet_df.columns = ['time', 'text', 'retweet_count', 'favorite_count', 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert datetime string to datetime data type\n",
    "tweet_df['time'] = pd.to_datetime(tweet_df['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df.drop_duplicates(subset='text', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df['target'] = 1\n",
    "# target value to be updated on csv file based on relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>text</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2019-11-01 21:38:55</td>\n",
       "      <td>RT @Christian_lxpez: MARIA FIRE UPDATE ! https...</td>\n",
       "      <td>239</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-11-01 21:38:09</td>\n",
       "      <td>RT @KTLA: The #MariaFire exploded across South...</td>\n",
       "      <td>514</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-11-01 21:37:45</td>\n",
       "      <td>RT @WCKitchen: UPDATE from the #MariaFire in V...</td>\n",
       "      <td>338</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-11-01 21:37:32</td>\n",
       "      <td>RT @SpecNews1SoCal: UPDATE: More new #MariaFir...</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019-11-01 21:37:27</td>\n",
       "      <td>RT @yamphoto: A study in hose action: firefigh...</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time                                               text  \\\n",
       "0 2019-11-01 21:38:55  RT @Christian_lxpez: MARIA FIRE UPDATE ! https...   \n",
       "1 2019-11-01 21:38:09  RT @KTLA: The #MariaFire exploded across South...   \n",
       "2 2019-11-01 21:37:45  RT @WCKitchen: UPDATE from the #MariaFire in V...   \n",
       "3 2019-11-01 21:37:32  RT @SpecNews1SoCal: UPDATE: More new #MariaFir...   \n",
       "4 2019-11-01 21:37:27  RT @yamphoto: A study in hose action: firefigh...   \n",
       "\n",
       "   retweet_count  favorite_count  target  \n",
       "0            239               0       1  \n",
       "1            514               0       1  \n",
       "2            338               0       1  \n",
       "3             26               0       1  \n",
       "4            192               0       1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df.to_csv('../data/maria_fire_20191101.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Using GetOldTweets3 Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used GeltOldTweets3 library to scrape tweets older than 7 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import GetOldTweets3 as got\n",
    "import codecs\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pypi.org/project/GetOldTweets3/\n",
    "    \n",
    "# define a functions that takes parameters and passes them to getTweets() method\n",
    "# then creates a list of tweet dictionaries\n",
    "def scrape_tweets(scrape_information):\n",
    "    tweets = got.manager.TweetManager.getTweets(scrape_information)\n",
    "    tweets_list = []\n",
    "    for tweet in tweets:\n",
    "        scraped_tweets = {}\n",
    "        scraped_tweets['tweet'] = tweet.text\n",
    "        tweets_list.append(scraped_tweets)\n",
    "    return tweets_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keyword = 'fire'\n",
    "parameters = got.manager.TweetCriteria()\\\n",
    "                .setMaxTweets(10000)\\\n",
    "                .setSince('2019-08-20')\\\n",
    "                .setUntil('2019-09-06')\\\n",
    "                .setNear('34.1826,-118.4397')\\\n",
    "                .setWithin('30mi');\n",
    "prefire_tweets = scrape_tweets(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6626 Norwich Avenuepic.twitter.com/X3ubOVlf8O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>This was an awesome find by @MitchTheFort. So ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>#MrKrabsMeme @North Hollywood, California http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Just posted a photo @North Hollywood, Californ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Check it out! Carnival Row Orlando Bloom Cara ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet\n",
       "0      6626 Norwich Avenuepic.twitter.com/X3ubOVlf8O\n",
       "1  This was an awesome find by @MitchTheFort. So ...\n",
       "2  #MrKrabsMeme @North Hollywood, California http...\n",
       "3  Just posted a photo @North Hollywood, Californ...\n",
       "4  Check it out! Carnival Row Orlando Bloom Cara ..."
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe\n",
    "prefire_tweets = pd.DataFrame(prefire_tweets)\n",
    "prefire_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign appropriate column names\n",
    "prefire_tweets.columns = ['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set datetime valeu same as filter parameter\n",
    "prefire_tweets['time'] = '2019-08-20 10:00:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert datetime string to datetime data type\n",
    "prefire_tweets['time'] = pd.to_datetime(prefire_tweets['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicate tweets \n",
    "prefire_tweets.drop_duplicates(subset='text', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set target value as 0\n",
    "prefire_tweets['target'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefire_tweets.to_csv('../data/prefire_tweets.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
